<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>音響通信 - 送受信デモ (v25 - 絶対同期版)</title>
    <style>
        body {
            font-family: sans-serif;
            padding: 1em;
        }

        .container {
            max-width: 600px;
            margin: auto;
        }

        .section {
            border: 1px solid #ccc;
            border-radius: 8px;
            padding: 16px;
            margin-bottom: 16px;
        }

        h2 {
            margin-top: 0;
        }

        input[type="text"] {
            width: 90%;
            padding: 8px;
            margin-bottom: 8px;
        }

        button {
            padding: 10px 15px;
            font-size: 16px;
            margin-right: 8px;
        }

        #resetButton {
            background: #ffc107;
        }

        #status-rx {
            color: #007bff;
        }

        #status-tx {
            color: #28a745;
        }

        #binaryResult {
            word-break: break-all;
        }

        #textResult {
            color: #dc3545;
            font-weight: bold;
        }

        #charLog {
            height: 100px;
            overflow-y: scroll;
            border: 1px solid #eee;
            padding: 5px;
            background: #f8f9fa;
        }

        .log-entry {
            margin-bottom: 3px;
        }

        .log-tx {
            color: #007bff;
            font-weight: bold;
        }

        .log-rx {
            color: #dc3545;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>音響通信 (送受信デモ)</h1>
        <p style="background: #fff3cd; border: 1px solid #ffeeba; padding: 10px; border-radius: 5px;">
            ⚠️ **注意: PCのスピーカー音量を100%に設定してください。**
        </p>

        <div class="section">
            <h2>送信側 (Sender)</h2>
            <input type="text" id="urlInput" value="https://www.teu.ac.jp/" style="width: 300px;">
            <button id="sendButton">送信</button>
            <p>ステータス: <span id="status-tx">待機中</span></p>
        </div>

        <div class="section">
            <h2>受信側 (Receiver)</h2>
            <button id="listenButton">受信開始</button>
            <button id="resetButton">リセット</button>
            <p>ステータス: <span id="status-rx">待機中</span></p>
            <p><b>受信バイナリ:</b> <span id="binaryResult"></span></p>
            <p><b>受信テキスト:</b> <span id="textResult"></span></p>

            <h4>受信ログ (比較用)</h4>
            <div id="charLog"></div>

            <p style="font-size: 0.8em; color: #666; margin-top: 15px;">（HTMLデバッグ: <span id="debug-volume">...</span>）
            </p>
        </div>
    </div>

    <script>
        // --- 共通設定 (v17の安定設定) ---
        const FREQ_0 = 1750; // '0' の周波数 (Hz)
        const FREQ_1 = 2000; // '1' の周波数 (Hz)
        const FREQ_START = 1500; // 開始信号
        const FREQ_END = 2250; // 終了信号 (分離)

        const START_DURATION = 500; // 開始信号の長さ (ミリ秒)
        const END_DURATION = 500;   // 終了信号の長さ (ミリ秒)
        const BIT_DURATION = 400; // 1ビットあたりの再生時間 (ミリ秒)
        const CHAR_PAUSE = 400; // 文字間ポーズ

        const THRESHOLD = -85; // 成功したしきい値を維持
        // ---

        // === UI要素 (グローバル) ===
        const sendButton = document.getElementById('sendButton');
        const urlInput = document.getElementById('urlInput');
        const statusTx = document.getElementById('status-tx');
        const listenButton = document.getElementById('listenButton');
        const statusRx = document.getElementById('status-rx');
        const binaryResult = document.getElementById('binaryResult');
        const textResult = document.getElementById('textResult');
        const debugVolume = document.getElementById('debug-volume');
        const resetButton = document.getElementById('resetButton');
        const charLog = document.getElementById('charLog');


        // === 送信側 (SENDER) のロジック ===
        let txAudioContext;

        async function playTone(frequency, duration) {
            if (!txAudioContext || txAudioContext.state === 'closed') {
                txAudioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            const oscillator = txAudioContext.createOscillator();
            oscillator.type = 'sine';
            oscillator.frequency.setValueAtTime(frequency, txAudioContext.currentTime);

            const gainNode = txAudioContext.createGain();
            gainNode.gain.setValueAtTime(0, txAudioContext.currentTime);
            gainNode.gain.linearRampToValueAtTime(1.0, txAudioContext.currentTime + 0.01);
            gainNode.gain.linearRampToValueAtTime(0, txAudioContext.currentTime + (duration / 1000) - 0.01);

            oscillator.connect(gainNode);
            gainNode.connect(txAudioContext.destination);

            oscillator.start(txAudioContext.currentTime);
            oscillator.stop(txAudioContext.currentTime + (duration / 1000));

            return new Promise(resolve => setTimeout(resolve, duration));
        }

        function stringToBinaryArray(str) {
            return str.split('').map(char => {
                const bin = char.charCodeAt(0).toString(2);
                return '0'.repeat(8 - bin.length) + bin;
            });
        }

        sendButton.onclick = async () => {
            if (txAudioContext && txAudioContext.state === 'running') {
                await txAudioContext.close();
            }

            const textToSend = urlInput.value;
            if (!textToSend) {
                alert('送信するテキストを入力してください');
                return;
            }

            const logEntry = document.createElement('div');
            logEntry.className = 'log-entry log-tx';
            logEntry.textContent = `[送信 S:] ${textToSend}`;
            charLog.appendChild(logEntry);
            charLog.scrollTop = charLog.scrollHeight;

            const binaryChars = stringToBinaryArray(textToSend);
            statusTx.textContent = '送信中...';
            sendButton.disabled = true;

            await playTone(FREQ_START, START_DURATION);

            for (const charBits of binaryChars) {
                for (const bit of charBits) {
                    const freq = (bit === '0') ? FREQ_0 : FREQ_1;
                    await playTone(freq, BIT_DURATION);
                }
                await new Promise(resolve => setTimeout(resolve, CHAR_PAUSE));
            }

            await playTone(FREQ_END, END_DURATION);

            statusTx.textContent = `送信完了: ${binaryChars.length * 8} ビット`;
            sendButton.disabled = false;
        };

        // === 受信側 (RECEIVER) のロジック ===
        let rxAudioContext;
        let analyser;
        let microphoneStream;
        let dataArray;
        let isListening = false;
        let receivedBinary = '';

        let receiveState = 'IDLE';
        let nextBitStartTime = 0;
        let expectedChars = 0;
        let bitsReceived = 0;
        // ▼▼▼ 絶対時刻の基準点を追加 ▼▼▼
        let absoluteStartTime = 0;

        function binaryToString(bin) {
            let str = '';
            for (let i = 0; i < bin.length; i += 8) {
                const byte = bin.substr(i, 8);
                if (byte.length === 8) {
                    str += String.fromCharCode(parseInt(byte, 2));
                }
            }
            return str;
        }

        function analyze() {
            if (!isListening) return;
            requestAnimationFrame(analyze);

            analyser.getFloatFrequencyData(dataArray);

            const targetBinSize = rxAudioContext.sampleRate / analyser.fftSize;

            const freq0Index = Math.round(FREQ_0 / targetBinSize);
            const freq1Index = Math.round(FREQ_1 / targetBinSize);
            const freqStartIndex = Math.round(FREQ_START / targetBinSize);
            const freqEndIndex = Math.round(FREQ_END / targetBinSize);

            const freq0Db = dataArray[freq0Index];
            const freq1Db = dataArray[freq1Index];
            const freqStartDb = dataArray[freqStartIndex];
            const freqEndDb = dataArray[freqEndIndex];

            const now = Date.now();

            debugVolume.textContent = `Start(1.5k): ${freqStartDb.toFixed(1)}, F0(1.75k): ${freq0Db.toFixed(1)}, F1(2.0k): ${freq1Db.toFixed(1)}, End(2.25k): ${freqEndDb.toFixed(1)}`;

            // 1. 待機状態 (IDLE): スタート信号を探す
            if (receiveState === 'IDLE') {
                if (freqStartDb > THRESHOLD && freqStartDb > freq0Db && freqStartDb > freq1Db && freqStartDb > freqEndDb) {
                    console.log(`--- スタート信号(1.5k)を検出！ (${freqStartDb.toFixed(1)}dB) ---`);
                    statusRx.textContent = '受信開始！';
                    receiveState = 'RECEIVING';

                    absoluteStartTime = now; // ▼ 絶対時刻の基準点を記録
                    expectedChars = urlInput.value.length;
                    bitsReceived = 0;

                    receivedBinary = '';
                    binaryResult.textContent = '';
                    textResult.textContent = '';

                    // 次のビット(Bit 0)のサンプリング時刻を設定
                    // (スタート信号終了 + 1ビット目の中間地点)
                    nextBitStartTime = absoluteStartTime + (START_DURATION - 50) + (BIT_DURATION / 2);
                }
            }
            // 2. 受信状態 (RECEIVING): 決まった時刻にのみ判定
            else if (receiveState === 'RECEIVING') {

                // サンプリング時刻（nextBitStartTime）を過ぎたか？
                if (now > nextBitStartTime) {

                    let bit = '';

                    // '0' の信号(1.75k)か？
                    if (freq0Db > THRESHOLD && freq0Db > freqStartDb && freq0Db > freq1Db && freq0Db > freqEndDb) {
                        bit = '0';
                        console.log(`ビット ${bitsReceived}: '0' (1.75k) を検出 (${freq0Db.toFixed(1)}dB)`);
                    }
                    // '1' の信号(2.0k)か？
                    else if (freq1Db > THRESHOLD && freq1Db > freqStartDb && freq1Db > freq0Db && freq1Db > freqEndDb) {
                        bit = '1';
                        console.log(`ビット ${bitsReceived}: '1' (2.0k) を検出 (${freq1Db.toFixed(1)}dB)`);
                    }
                    // 信号が弱すぎる (ノイズ抑制された)
                    else {
                        bit = '?'; // 不明なビット
                        console.log(`ビット ${bitsReceived}: 信号検出失敗 (音量不足)`);
                    }

                    receivedBinary += bit;
                    binaryResult.textContent = receivedBinary;
                    bitsReceived++;

                    // 予定していた全ビットを受信したら、終了信号の待機に移る
                    if (bitsReceived >= (expectedChars * 8)) {
                        console.log("--- 全ビット受信完了、終了信号待機... ---");
                        receiveState = 'WAIT_END';

                        // ▼ 終了信号の「絶対時刻」を計算
                        const charsReceived = bitsReceived / 8;
                        const pausesSoFar = Math.max(0, charsReceived); // 最後の文字の後にもポーズがある
                        nextBitStartTime = absoluteStartTime + START_DURATION + (BIT_DURATION * bitsReceived) + (CHAR_PAUSE * pausesSoFar) + (END_DURATION / 2);

                    } else {
                        // ▼ 次のビットの「絶対時刻」を再計算
                        const charsSoFar = Math.floor(bitsReceived / 8);
                        const pausesSoFar = charsSoFar; // 1文字(8bit)ごとにポーズ
                        nextBitStartTime = absoluteStartTime + (START_DURATION - 50) + (BIT_DURATION * (bitsReceived + 0.5)) + (CHAR_PAUSE * pausesSoFar);
                    }

                    // 1文字(8bit)受信したか？
                    if (bitsReceived > 0 && bitsReceived % 8 === 0) {
                        const lastByte = receivedBinary.slice(-8);
                        const lastChar = binaryToString(lastByte);

                        textResult.textContent = binaryToString(receivedBinary);

                        const logEntry = document.createElement('div');
                        logEntry.className = 'log-entry log-rx';
                        logEntry.textContent = `[受信 R:] ${lastChar} (バイナリ: ${lastByte})`;
                        charLog.appendChild(logEntry);
                        charLog.scrollTop = charLog.scrollHeight;

                        console.log(`--- 1文字認識: ${lastChar} ---`);
                    }
                }
            }
            // 3. 終了待機状態 (WAIT_END)
            else if (receiveState === 'WAIT_END') {
                if (now > nextBitStartTime) {
                    if (freqEndDb > THRESHOLD && freqEndDb > freqStartDb && freqEndDb > freq0Db && freqEndDb > freq1Db) {
                        console.log(`--- 終了信号(2.25k)を検出！ (${freqEndDb.toFixed(1)}dB) ---`);
                        statusRx.textContent = '受信完了（終了信号受信）';
                        receiveState = 'IDLE';
                    } else {
                        console.log("--- 終了信号の検出に失敗 ---");
                        statusRx.textContent = '受信完了（終了信号なし）';
                        receiveState = 'IDLE';
                    }
                }
            }
        }

        async function startListening() {
            try {
                const constraints = {
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    },
                    video: false
                };
                microphoneStream = await navigator.mediaDevices.getUserMedia(constraints);

                rxAudioContext = new (window.AudioContext || window.webkitAudioContext)();

                analyser = rxAudioContext.createAnalyser();
                analyser.fftSize = 2048;
                dataArray = new Float32Array(analyser.frequencyBinCount);

                const source = rxAudioContext.createMediaStreamSource(microphoneStream);
                source.connect(analyser);

                isListening = true;
                listenButton.textContent = '受信停止';
                statusRx.textContent = '開始信号を待っています...';
                analyze();

            } catch (err) {
                alert('マイクの取得に失敗しました: ' + err.message);
            }
        }

        function stopListening() {
            isListening = false;
            receiveState = 'IDLE';
            listenButton.textContent = '受信開始';
            statusRx.textContent = '待機中';
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
            }
            if (rxAudioContext && rxAudioContext.state !== 'closed') {
                rxAudioContext.close();
            }
        }

        listenButton.onclick = () => {
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        };

        resetButton.onclick = () => {
            receivedBinary = '';
            binaryResult.textContent = '';
            textResult.textContent = '';
            charLog.innerHTML = '';
            statusRx.textContent = 'リセットしました';
            if (isListening) {
                receiveState = 'IDLE';
                bitsReceived = 0;
                expectedChars = 0;
                absoluteStartTime = 0; // ▼ 追加
            }
        };

    </script>
</body>

</html>