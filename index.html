<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>音響通信 - 送受信デモ (v14 - 環境最適化版)</title>
    <style>
        body {
            font-family: sans-serif;
            padding: 1em;
        }

        .container {
            max-width: 600px;
            margin: auto;
        }

        .section {
            border: 1px solid #ccc;
            border-radius: 8px;
            padding: 16px;
            margin-bottom: 16px;
        }

        h2 {
            margin-top: 0;
        }

        input[type="text"] {
            width: 90%;
            padding: 8px;
            margin-bottom: 8px;
        }

        button {
            padding: 10px 15px;
            font-size: 16px;
            margin-right: 8px;
        }

        #status-rx {
            color: #007bff;
        }

        #status-tx {
            color: #28a745;
        }

        #binaryResult {
            word-break: break-all;
        }

        #textResult {
            color: #dc3545;
            font-weight: bold;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>音響通信 (送受信デモ)</h1>
        <p style="background: #fff3cd; border: 1px solid #ffeeba; padding: 10px; border-radius: 5px;">
            ⚠️ **注意: PCのスピーカー音量を100%に設定してください。**
        </p>

        <div class="section">
            <h2>送信側 (Sender)</h2>
            <input type="text" id="urlInput" value="abc" style="width: 300px;">
            <button id="sendButton">送信</button>
            <p>ステータス: <span id="status-tx">待機中</span></p>
        </div>

        <div class="section">
            <h2>受信側 (Receiver)</h2>
            <button id="listenButton">受信開始</button>
            <p>ステータス: <span id="status-rx">待機中</span></p>
            <p><b>受信バイナリ:</b> <span id="binaryResult"></span></p>
            <p><b>受信テキスト:</b> <span id="textResult"></span></p>
            <p style="font-size: 0.8em; color: #666;">（HTMLデバッグ: <span id="debug-volume">...</span>）</p>
        </div>
    </div>

    <script>
        // --- 共通設定 (▼▼▼ 環境最適化 ▼▼▼) ---
        const FREQ_0 = 1500; // '0' の周波数 (Hz)
        const FREQ_1 = 2000; // '1' の周波数 (Hz)
        const FREQ_START = 1750; // 開始信号 (最も通りやすい周波数)
        const FREQ_END = 2250; // 終了信号の周波数 (Hz)

        const START_DURATION = 500; // 開始信号の長さ (ミリ秒)
        const END_DURATION = 500;   // 終了信号の長さ (ミリ秒)
        const BIT_DURATION = 500; // 1ビットあたりの再生時間 (ミリ秒)

        // ▼▼▼ しきい値をノイズフロアの直上(-100)に設定 ▼▼▼
        const THRESHOLD = -100;
        // ---

        // === 送信側 (SENDER) のロジック ===
        const sendButton = document.getElementById('sendButton');
        const urlInput = document.getElementById('urlInput');
        const statusTx = document.getElementById('status-tx');

        let txAudioContext;

        async function playTone(frequency, duration) {
            if (!txAudioContext || txAudioContext.state === 'closed') {
                txAudioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            const oscillator = txAudioContext.createOscillator();
            oscillator.type = 'sine';
            oscillator.frequency.setValueAtTime(frequency, txAudioContext.currentTime);

            const gainNode = txAudioContext.createGain();
            gainNode.gain.setValueAtTime(0, txAudioContext.currentTime);
            gainNode.gain.linearRampToValueAtTime(1.0, txAudioContext.currentTime + 0.01); // 音量最大
            gainNode.gain.linearRampToValueAtTime(0, txAudioContext.currentTime + (duration / 1000) - 0.01);

            oscillator.connect(gainNode);
            gainNode.connect(txAudioContext.destination);

            oscillator.start(txAudioContext.currentTime);
            oscillator.stop(txAudioContext.currentTime + (duration / 1000));

            return new Promise(resolve => setTimeout(resolve, duration));
        }

        function stringToBinary(str) {
            return str.split('').map(char => {
                const bin = char.charCodeAt(0).toString(2);
                return '0'.repeat(8 - bin.length) + bin;
            }).join('');
        }

        sendButton.onclick = async () => {
            if (txAudioContext && txAudioContext.state === 'running') {
                await txAudioContext.close();
            }

            const textToSend = urlInput.value;
            if (!textToSend) {
                alert('送信するテキストを入力してください');
                return;
            }

            const binaryData = stringToBinary(textToSend);
            statusTx.textContent = '送信中...';
            sendButton.disabled = true;

            await playTone(FREQ_START, START_DURATION); // 1. 開始信号
            for (const bit of binaryData) { // 2. データ信号
                const freq = (bit === '0') ? FREQ_0 : FREQ_1;
                await playTone(freq, BIT_DURATION);
            }
            await playTone(FREQ_END, END_DURATION); // 3. 終了信号

            statusTx.textContent = `送信完了: ${binaryData.length} ビット`;
            sendButton.disabled = false;
        };

        // === 受信側 (RECEIVER) のロジック ===
        const listenButton = document.getElementById('listenButton');
        const statusRx = document.getElementById('status-rx');
        const binaryResult = document.getElementById('binaryResult');
        const textResult = document.getElementById('textResult');
        const debugVolume = document.getElementById('debug-volume');

        let rxAudioContext;
        let analyser;
        let microphoneStream;
        let dataArray;
        let isListening = false;
        let receivedBinary = '';
        let lastBitTime = 0;
        let receiveState = 'IDLE';

        function binaryToString(bin) {
            let str = '';
            for (let i = 0; i < bin.length; i += 8) {
                const byte = bin.substr(i, 8);
                if (byte.length === 8) {
                    str += String.fromCharCode(parseInt(byte, 2));
                }
            }
            return str;
        }

        function analyze() {
            if (!isListening) return;
            requestAnimationFrame(analyze);

            analyser.getFloatFrequencyData(dataArray);

            const targetBinSize = rxAudioContext.sampleRate / analyser.fftSize;

            const freq0Index = Math.round(FREQ_0 / targetBinSize);
            const freq1Index = Math.round(FREQ_1 / targetBinSize);
            const freqStartIndex = Math.round(FREQ_START / targetBinSize);
            const freqEndIndex = Math.round(FREQ_END / targetBinSize);

            const freq0Db = dataArray[freq0Index];
            const freq1Db = dataArray[freq1Index];
            const freqStartDb = dataArray[freqStartIndex];
            const freqEndDb = dataArray[freqEndIndex];

            const now = Date.now();

            debugVolume.textContent = `Start(1.75k): ${freqStartDb.toFixed(1)}, F0(1.5k): ${freq0Db.toFixed(1)}, F1(2.0k): ${freq1Db.toFixed(1)}, End(2.25k): ${freqEndDb.toFixed(1)}`;

            // 1. 待機状態 (IDLE): スタート信号を探す
            if (receiveState === 'IDLE') {
                if (freqStartDb > THRESHOLD && freqStartDb > freq0Db && freqStartDb > freq1Db && freqStartDb > freqEndDb) {
                    console.log(`--- スタート信号(1.75k)を検出！ (${freqStartDb.toFixed(1)}dB) ---`);
                    statusRx.textContent = '受信開始！';
                    receiveState = 'RECEIVING';
                    receivedBinary = '';
                    binaryResult.textContent = '';
                    textResult.textContent = '';
                    lastBitTime = now + (START_DURATION - 50);
                }
            }
            // 2. 受信状態 (RECEIVING): 0, 1, または終了信号を探す
            else if (receiveState === 'RECEIVING') {

                if (now - lastBitTime > (BIT_DURATION - 50)) { // 450ms 以上経過したら

                    let bit = '';

                    // 終了信号か？
                    if (freqEndDb > THRESHOLD && freqEndDb > freqStartDb && freqEndDb > freq0Db && freqEndDb > freq1Db) {
                        console.log(`--- 終了信号(2.25k)を検出！ (${freqEndDb.toFixed(1)}dB) ---`);
                        statusRx.textContent = '受信完了（終了信号受信）';
                        receiveState = 'IDLE';
                        return;
                    }

                    // '0' の信号か？
                    else if (freq0Db > THRESHOLD && freq0Db > freqStartDb && freq0Db > freq1Db && freq0Db > freqEndDb) {
                        bit = '0';
                        console.log(`ビット '0' (1.5k) を検出 (${freq0Db.toFixed(1)}dB)`);
                    }

                    // '1' の信号か？
                    else if (freq1Db > THRESHOLD && freq1Db > freqStartDb && freq1Db > freq0Db && freq1Db > freqEndDb) {
                        bit = '1';
                        console.log(`ビット '1' (2.0k) を検出 (${freq1Db.toFixed(1)}dB)`);
                    }

                    // どれでもない場合 (無音またはノイズ)
                    else {
                        if (now - lastBitTime > 2500) { // 2.5秒間無音なら
                            console.log("--- タイムアウト ---");
                            statusRx.textContent = '受信完了（タイムアウト）';
                            receiveState = 'IDLE';
                            return;
                        }
                        return; // 判定をスキップ
                    }

                    receivedBinary += bit;
                    binaryResult.textContent = receivedBinary;
                    lastBitTime = now;

                    if (receivedBinary.length % 8 === 0) {
                        textResult.textContent = binaryToString(receivedBinary);
                    }
                }
            }
        }

        async function startListening() {
            try {
                const constraints = {
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    },
                    video: false
                };
                microphoneStream = await navigator.mediaDevices.getUserMedia(constraints);

                rxAudioContext = new (window.AudioContext || window.webkitAudioContext)();

                analyser = rxAudioContext.createAnalyser();
                analyser.fftSize = 2048;
                dataArray = new Float32Array(analyser.frequencyBinCount);

                const source = rxAudioContext.createMediaStreamSource(microphoneStream);
                source.connect(analyser);

                isListening = true;
                listenButton.textContent = '受信停止';
                statusRx.textContent = '開始信号を待っています...';
                analyze();

            } catch (err) {
                alert('マイクの取得に失敗しました: ' + err.message);
            }
        }

        function stopListening() {
            isListening = false;
            receiveState = 'IDLE';
            listenButton.textContent = '受信開始';
            statusRx.textContent = '待機中';
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
            }
            if (rxAudioContext && rxAudioContext.state !== 'closed') {
                rxAudioContext.close();
            }
        }

        listenButton.onclick = () => {
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        };

    </script>
</body>

</html>